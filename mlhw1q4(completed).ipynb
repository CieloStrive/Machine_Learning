{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlhw1q4(completed).ipynbb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "190Tw6y7COs1",
        "colab_type": "text"
      },
      "source": [
        "Homework Q4:\n",
        "\n",
        "ps:some print() of values like tf idf tf-idf have been changes into comment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH9QeYx4tFN3",
        "colab_type": "text"
      },
      "source": [
        "Part (a) :\n",
        "\n",
        "define an function to read each document and convert it into a vector of words and obtain appearance time of each word, tf of each word and a list of all kinds of word in each .txt document saving as dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxAv3ORASeMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#upload text to colab first\n",
        "\n",
        "def preprocess(x):\n",
        "  import string\n",
        "  with open (x, 'r+') as f:\n",
        "    filestr=f.read()\n",
        "  \n",
        "  #convert words into a vector :\n",
        "  words = ''.join(c for c in filestr if c not in string.punctuation)#remove punctuation\n",
        "  words = words.lower()#convert all letters to lowercase\n",
        "  words = words.split()#split words by blank or \\n\n",
        "  #print(words)\n",
        "  \n",
        "  #appearance time of each word :\n",
        "  count = {} \n",
        "  for n in range(0,len(words)):\n",
        "    count[ words[n] ] = words.count( words[n] )\n",
        "  #print(count)\n",
        "  \n",
        "  #tf of each word :\n",
        "  tf = {}\n",
        "  for k,v in count.items():\n",
        "    tf[k] =  v / len(words) \n",
        "  \n",
        "  return [count,tf,words]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BSojvePuCmE",
        "colab_type": "text"
      },
      "source": [
        "Part (b) :\n",
        "\n",
        "b1. write a function to obtain result of function \"preprocess\" on each document from paths provided in a list and put appearance counter of words, tf of words in every document and a collection of all kinds of words appear in all documents  respectively into three lists : counter, tfdic, all_words\n",
        "\n",
        "*click files on the left bar and upload test documents\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03Ii31xcUQ7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def obtain(path):\n",
        "  counter = []\n",
        "  tfdic = []\n",
        "  i = 1\n",
        "  all_words = set() \n",
        "  for n in path:\n",
        "    counter.append( preprocess(n)[0] )\n",
        "    tfdic.append( preprocess(n)[1] )\n",
        "    all_words = all_words.union( set(preprocess(n)[2]) )\n",
        "  return [counter,tfdic,all_words]  \n",
        "\n",
        "paths = ['d_query.txt','d1.txt','d2.txt','d3.txt','d4.txt','d5.txt']\n",
        "counter = obtain(paths)[0]\n",
        "tfdic = obtain(paths)[1]\n",
        "all_words = obtain(paths)[2]\n",
        "docnumber = len(paths)\n",
        "#print (\"all words:\",all_words)\n",
        "#print()  \n",
        "#for i in range(1,docnumber): \n",
        "#  print(\"appearance time of words in d\"+str(i)+\":\",counter[i])\n",
        "#   print(\"time frequency of words in d\"+str(i)+\":\",tfdic[i])\n",
        "#   print(\"size:\",len(tfdic[i]))\n",
        "#  print()\n",
        "# print(\"appearance time of words in d_query:\",counter[0])\n",
        "# print(\"time frequency of words in d_query:\",tfdic[0])\n",
        "# print(\"size:\",len(tfdic[0]))  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41FrZuOxHKpU",
        "colab_type": "text"
      },
      "source": [
        "b2.write a function to unify the format of counter and tfdic to make every dictionary have same attributes and dimension, put them respectively into two lists: counters, tfdics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtkhFPVGHgdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unifydics(aim):\n",
        "  l = aim\n",
        "  result = []\n",
        "  for n in range(0,len(l)):\n",
        "    for x in all_words:\n",
        "      if x not in l[n]:\n",
        "        l[n][x]=0\n",
        "    keys = sorted(l[n].keys()) \n",
        "    ks = {}\n",
        "    for k in keys:\n",
        "      ks[k] = l[n][k]\n",
        "    result.append(ks)\n",
        "  return result      \n",
        "\n",
        "counters = unifydics (counter)\n",
        "tfdics = unifydics (tfdic)\n",
        "\n",
        "# for i in range(1,docnumber): \n",
        "#   print()\n",
        "#   print(\"unified A.T. of words in d\"+str(i)+\":\",counters[i])\n",
        "#   print(\"unified tf of words in d\"+str(i)+\":\",tfdics[i])\n",
        "#   print(\"size:\",len(tfdics[i]))\n",
        "# print()\n",
        "# print(\"unified A.T. of words in d_query:\",counters[0])\n",
        "# print(\"unified tf of words in d_query:\",tfdics[0])  \n",
        "# print(\"size:\",len(tfdics[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNTuVfozuvh9",
        "colab_type": "text"
      },
      "source": [
        "b3. write a function to obtain idf of each words in every document and put them together into one list : idfdics , actually they are all the same but I save them as the same format and container as tf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "socJbR-OZ8wl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getidf(counters):\n",
        "  import math\n",
        "  idfdics = []\n",
        "  docnumber = len(counters)\n",
        "  for n in range(0,docnumber):\n",
        "    idf = {}\n",
        "    for k,v in counters[n].items():\n",
        "      c=0\n",
        "      for m in range(0,docnumber):\n",
        "        if counters[m][k] != 0 :\n",
        "          c = c + 1\n",
        "      if c == 0:\n",
        "        c = c + 1 #in case c == 0    \n",
        "      idf[k] = math.log10(docnumber / c )\n",
        "    idfdics.append(idf)  \n",
        "  return idfdics\n",
        "\n",
        "idfdics = getidf(counters)\n",
        "\n",
        "# for n in range(1,docnumber):\n",
        "#   print(\"inverse document frequency of words in d\"+str(n)+\":\",idfdics[i])\n",
        "# print(\"inverse document frequency of words in d_query:\",idfdics[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGda4s2ExmXu",
        "colab_type": "text"
      },
      "source": [
        "b4. write a funtion to obtain tf-idf of each words in every document and put them together into one list : tfidfdics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hEZ47sgvBL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gettfidf(tfdics,idfdics):\n",
        "  tfidfdics = []\n",
        "  for n in range(0,docnumber):\n",
        "    tfidf = {}\n",
        "    for k,v in tfdics[n].items():\n",
        "      tfidf[k] = tfdics[n][k] * idfdics[n][k]\n",
        "    # print(tfidf)\n",
        "    tfidfdics.append(tfidf)\n",
        "  return tfidfdics\n",
        "\n",
        "tfidfdics = gettfidf(tfdics,idfdics)\n",
        "\n",
        "#for n in range(1,docnumber):\n",
        "#  print(\"tf-idf of words in d\"+str(n)+\":\",tfidfdics[n])\n",
        "#print(\"tf-idf of words in d_query:\",tfidfdics[0])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgCllb5YzPfW",
        "colab_type": "text"
      },
      "source": [
        "Part (c) :\n",
        "\n",
        "define a function that can calculate cosine similarity between two dictionaries of tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX8uq9mC3vXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosinesimilarity(x,y):\n",
        "  if len(x) != len(y):\n",
        "    print(\"dimension does not match\")\n",
        "    return 0\n",
        "  \n",
        "  import numpy as np\n",
        "  product = 0\n",
        "  squarex = 0\n",
        "  squarey = 0\n",
        "  for kx,ky in zip(x.keys(),y.keys()):\n",
        "    product = product + x[kx]*y[ky]\n",
        "    squarex = squarex + np.square(x[kx])\n",
        "    squarey = squarey + np.square(y[ky])\n",
        "   \n",
        "  euclideanx = np.sqrt(squarex) \n",
        "  euclideany = np.sqrt(squarey)\n",
        "  similarity = product / ( euclideanx * euclideany )\n",
        "  \n",
        "  # print(\"product: \",product,\" euclideanx: \",euclideanx,\" euclideany: \",euclideany,\" similarity = product / (euclideanx * euclideany): \",similarity)\n",
        "  # print()\n",
        "  return similarity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiLsydlFBEnJ",
        "colab_type": "text"
      },
      "source": [
        "Part (d) :\n",
        "\n",
        "define a recognition function that can use function defined above to compare cosine similarity among documents and return sequence number of result document and maximum value of similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H8OpcPRBFGq",
        "colab_type": "code",
        "outputId": "310704c2-55e6-4c1d-fc7f-42eac44db671",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "def recognition(tfidfs):\n",
        "  similarity = []\n",
        "  for n in range(1,len(tfidfs)):\n",
        "    similarity.append( cosinesimilarity(tfidfs[0],tfidfs[n]) )\n",
        "  index = similarity.index(max(similarity))\n",
        "  maximum = max(similarity)  \n",
        "  #print(\"similarities: \",similarity)\n",
        "  print(\"d \"+str(index+1)+\" is the document with maximum cosine similarity value of \"+str(maximum))\n",
        "  print()\n",
        "  return [index+1,maximum]\n",
        "\n",
        "recognition(tfidfdics)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "d 4 is the documen with maximum cosine similarity value of 0.19616295821215432\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 0.19616295821215432]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    }
  ]
}